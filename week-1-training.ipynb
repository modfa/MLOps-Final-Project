{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3a71c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PREDICTING PRICE OF PRE-OWNED CARS \n",
    "# =============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cc3ffe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "056da6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.12\r\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88c67d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_pickle(obj, filename):\n",
    "    with open(filename, \"wb\") as f_out:\n",
    "        return pickle.dump(obj, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "396d9b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_Dataframe(path_to_df):\n",
    "    cars_data=pd.read_csv(path_to_df)\n",
    "    cars=cars_data.copy()\n",
    "    col=['name','dateCrawled','dateCreated','postalCode','lastSeen']\n",
    "    cars=cars.drop(columns=col, axis=1)\n",
    "    cars.drop_duplicates(keep='first',inplace=True)\n",
    "    cars = cars[\n",
    "            (cars.yearOfRegistration <= 2018) \n",
    "          & (cars.yearOfRegistration >= 1950) \n",
    "          & (cars.price >= 100) \n",
    "          & (cars.price <= 150000) \n",
    "          & (cars.powerPS >= 10) \n",
    "          & (cars.powerPS <= 500)]\n",
    "    cars['monthOfRegistration']/=12\n",
    "\n",
    "    # Creating new varible Age by adding yearOfRegistration and monthOfRegistration\n",
    "    cars['Age']=(2018-cars['yearOfRegistration'])+cars['monthOfRegistration']\n",
    "    cars['Age']=round(cars['Age'],2)\n",
    "\n",
    "    cars=cars.drop(columns=['yearOfRegistration','monthOfRegistration'], axis=1)\n",
    "    col=['seller','offerType','abtest']\n",
    "    cars=cars.drop(columns=col, axis=1)\n",
    "    cars_copy=cars.copy()\n",
    "    cars_omit=cars.dropna(axis=0)\n",
    "    x1 = cars_omit.drop(['price'], axis='columns', inplace=False)\n",
    "    y1 = cars_omit['price']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x1, y1, test_size=0.3, random_state = 3)\n",
    "    y_train = np.log(y_train.values)\n",
    "    y_test = np.log(y_test.values)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "    # print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "230f3b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df: pd.DataFrame, dv: DictVectorizer, fit_dv: bool = False):\n",
    "    categorical = ['vehicleType', 'gearbox','model', 'fuelType', 'brand', 'notRepairedDamage']\n",
    "    numerical = ['powerPS','kilometer','Age']\n",
    "\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "    dicts = df[categorical + numerical].to_dict(orient='records')\n",
    "    if fit_dv:\n",
    "        X = dv.fit_transform(dicts)\n",
    "    else:\n",
    "        X = dv.transform(dicts)\n",
    "    return X, dv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ccf47c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(raw_data_path: str, dest_path: str, dataset: str = \"cars_sampled.csv\"):\n",
    "    X_train, X_test, y_train, y_test = read_Dataframe(\n",
    "        os.path.join(raw_data_path, dataset))\n",
    "    \n",
    "    dv = DictVectorizer()\n",
    "    X_train, dv = preprocess(X_train, dv, fit_dv=True)\n",
    "    X_test, _ = preprocess(X_test, dv, fit_dv=False)\n",
    "    \n",
    "    \n",
    "     # create dest_path folder unless it already exists\n",
    "    os.makedirs(dest_path, exist_ok=True)\n",
    "\n",
    "    # save dictvectorizer and datasets\n",
    "    dump_pickle(dv, os.path.join(dest_path, \"dv.pkl\"))\n",
    "    dump_pickle((X_train, y_train), os.path.join(dest_path, \"train.pkl\"))\n",
    "#     dump_pickle((X_valid, y_valid), os.path.join(dest_path, \"valid.pkl\"))\n",
    "    dump_pickle((X_test, y_test), os.path.join(dest_path, \"test.pkl\"))\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7028690c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--raw_data_path\",\n",
    "        help=\"the location where the raw NYC taxi trip data was saved\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--dest_path\",\n",
    "        help=\"the location where the resulting files will be saved.\"\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    run(args.raw_data_path, args.dest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490ea9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = read_Dataframe('cars_sampled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f53c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = DictVectorizer()\n",
    "X_train, dv = preprocess(X_train, dv, fit_dv=True)\n",
    "X_test, _ = preprocess(X_test, dv, fit_dv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3467f347",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new\n",
    "# categorical = ['vehicleType', 'gearbox','model', 'fuelType', 'brand', 'notRepairedDamage']\n",
    "# numerical = ['powerPS','kilometer','Age']\n",
    "\n",
    "# X_train[categorical] = X_train[categorical].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500fd5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dv = DictVectorizer()\n",
    "# train_dicts = X_train[categorical + numerical].to_dict(orient='records')\n",
    "# X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "\n",
    "# test_dicts = X_test[categorical + numerical].to_dict(orient='records')\n",
    "# X_test = dv.transform(test_dicts)\n",
    "\n",
    "\n",
    "# # target = 'price'\n",
    "# y_train = np.log(y_train.values)\n",
    "# y_test = np.log(y_test.values)\n",
    "\n",
    "# lr = LinearRegression()\n",
    "# lr.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = lr.predict(X_train)\n",
    "\n",
    "# mean_squared_error(y_train, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703eeb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting intercept as true\n",
    "lgr=LinearRegression(fit_intercept=True)\n",
    "\n",
    "# Model\n",
    "model_lin1=lgr.fit(X_train,y_train)\n",
    "\n",
    "# Predicting model on test set\n",
    "cars_predictions_lin1 = lgr.predict(X_test)\n",
    "\n",
    "# Computing MSE and RMSE\n",
    "lin_mse1 = mean_squared_error(y_test, cars_predictions_lin1)\n",
    "lin_rmse1 = np.sqrt(lin_mse1)\n",
    "print(lin_rmse1)\n",
    "\n",
    "# R squared value\n",
    "r2_lin_test1=model_lin1.score(X_test,y_test)\n",
    "r2_lin_train1=model_lin1.score(X_train,y_train)\n",
    "print(r2_lin_test1,r2_lin_train1)\n",
    "\n",
    "# Regression diagnostics- Residual plot analysis\n",
    "residuals1=y_test-cars_predictions_lin1\n",
    "sns.regplot(x=cars_predictions_lin1, y=residuals1, scatter=True, \n",
    "            fit_reg=False)\n",
    "# residuals1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151a1a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(cars_predictions_lin1, label='prediction')\n",
    "sns.distplot(y_test, label='actual')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ab84cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15919c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# RANDOM FOREST WITH OMITTED DATA\n",
    "# =============================================================================\n",
    "\n",
    "# Model parameters\n",
    "rf = RandomForestRegressor(n_estimators = 100,max_features='auto',\n",
    "                           max_depth=100,min_samples_split=10,\n",
    "                           min_samples_leaf=4,random_state=1)\n",
    "\n",
    "# Model\n",
    "model_rf1=rf.fit(X_train,y_train)\n",
    "\n",
    "# Predicting model on test set\n",
    "cars_predictions_rf1 = rf.predict(X_test)\n",
    "\n",
    "# Computing MSE and RMSE\n",
    "rf_mse1 = mean_squared_error(y_test, cars_predictions_rf1)\n",
    "rf_rmse1 = np.sqrt(rf_mse1)\n",
    "print(rf_rmse1)\n",
    "\n",
    "# R squared value\n",
    "r2_rf_test1=model_rf1.score(X_test,y_test)\n",
    "r2_rf_train1=model_rf1.score(X_train,y_train)\n",
    "print(r2_rf_test1,r2_rf_train1)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4c75f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import mlflow\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08927036",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = xgb.DMatrix(X_train, label=y_train)\n",
    "valid = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c37efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"my-final-project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62af38bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag(\"model\", \"xgboost\")\n",
    "        mlflow.log_params(params)\n",
    "        booster = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=train,\n",
    "            num_boost_round=100,\n",
    "            evals=[(valid, 'validation')],\n",
    "            early_stopping_rounds=50\n",
    "        )\n",
    "        y_pred = booster.predict(valid)\n",
    "        rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    return {'loss': rmse, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5e2190",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 4, 100, 1)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -3, 0),\n",
    "    'reg_alpha': hp.loguniform('reg_alpha', -5, -1),\n",
    "    'reg_lambda': hp.loguniform('reg_lambda', -6, -1),\n",
    "    'min_child_weight': hp.loguniform('min_child_weight', -1, 3),\n",
    "    'objective': 'reg:linear',\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "best_search_result = {\n",
    "    'max_depth': 11,\n",
    "    'learning_rate': 0.11504139773734708,\n",
    "    'reg_alpha': 0.03143119240248877,\n",
    "    'reg_lambda': 0.0058914904219020325,\n",
    "    'min_child_weight': 9.242463709505468,\n",
    "    'objective': 'reg:linear',\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "best_result = fmin(\n",
    "    fn=objective,\n",
    "    space=best_search_result,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,\n",
    "    trials=Trials()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f413e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./lin_reg.bin', 'wb') as f_out:\n",
    "    pickle.dump( lgr, f_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cbeb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./random_forest.bin', 'wb') as f_out:\n",
    "    pickle.dump( rf, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2466ed98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42235601",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
